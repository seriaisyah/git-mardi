{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345eb9e8",
   "metadata": {
    "id": "7d0ecdd2"
   },
   "source": [
    "![alt](https://research.utm.my/wp-content/uploads/sites/26/2022/06/logo-300x122.png)\n",
    "# Center for Artificial Intelligence and Robotics\n",
    "### Universiti Teknologi Malaysia\n",
    "\n",
    "\n",
    "#### Classification Inference - Resnet50\n",
    "\n",
    "*Author: Dr. Ibrahim, Azzam, Thaqif & Syahmi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc0dd9",
   "metadata": {
    "id": "bcc851c1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8ae8e",
   "metadata": {
    "id": "1569e3fa"
   },
   "source": [
    "All pre-trained models expect input images normalized in the same way,\n",
    "i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n",
    "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
    "and `std = [0.229, 0.224, 0.225]`.\n",
    "\n",
    "Here's a sample execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac90a52",
   "metadata": {
    "id": "053ada83"
   },
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "# import urllib\n",
    "# url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "# try: urllib.URLopener().retrieve(url, filename)\n",
    "# except: urllib.request.urlretrieve(url, filename)\n",
    "# Load the image\n",
    "filename = \"test_images/cat_1.jpeg\"\n",
    "input_image = Image.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c87335",
   "metadata": {
    "id": "28d9d86f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model\n",
    "\n",
    "# Move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "    \n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "# Get probabilities\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b8c85",
   "metadata": {
    "id": "fb804a00"
   },
   "outputs": [],
   "source": [
    "# Download and read ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7bf31-80eb-4309-b979-6c137552d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "# Display the image after predictions\n",
    "plt.imshow(input_image)\n",
    "plt.axis('off')  # Hide the axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e971d",
   "metadata": {
    "id": "c9ee1b09",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model Description\n",
    "\n",
    "ResNet-50 is a deep residual network that has 50 layers. It was introduced in the paper \"Deep Residual Learning for Image Recognition\" and became one of the most widely used models in computer vision tasks.\n",
    "\n",
    "### References\n",
    "\n",
    " - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa32994-7897-4c37-9c3c-7ebb7293eb9d",
   "metadata": {},
   "source": [
    "# Plant Classification with ResNet-50\n",
    "\n",
    "This section demonstrates how to load a custom-trained ResNet-50 model on a Jetson device, and use it for plant classification. The model is configured to classify images into three categories.\n",
    "\n",
    "## Sections\n",
    "\n",
    "1. Prerequisites\n",
    "2. Import Necessary Libraries\n",
    "3. Set Up the Device\n",
    "4. Model Architecture\n",
    "5. Load the Model Weights\n",
    "6. Prediction Function\n",
    "    - Function Definition\n",
    "    - Usage\n",
    "7. Example Usage\n",
    "8. Conclusion\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297cead9-2c42-4719-94ac-776d467aae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessery libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure you are using the correct device (GPU on Jetson)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model architecture\n",
    "model = resnet50(pretrained=False)  # Set pretrained to False since we'll load custom weights\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)  # Adjust the output layer to match the number of classes\n",
    "\n",
    "# Load the model weights\n",
    "model_load_path = '___' # FIX ME # Replace with your model path\n",
    "model.load_state_dict(torch.load(model_load_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Prediction function (reuse from earlier)\n",
    "def predict_image(model, image_path, class_names):\n",
    "    \n",
    "    # Transform to match the training preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move the image to the device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1).cpu().numpy().squeeze()\n",
    "        predicted_idx = probabilities.argmax()\n",
    "    \n",
    "    predicted_class = class_names[predicted_idx]\n",
    "    confidence = probabilities[predicted_idx] * 100\n",
    "    result = f\"This image most likely belongs to {predicted_class} with a {confidence:.2f} percent confidence.\"\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.title(result)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return result, dict(zip(class_names, probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af857f2-1ff7-4021-9fcc-0f7dc1feec05",
   "metadata": {},
   "source": [
    "Hereâ€™s how you can use the predict_image function with actual class names and an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292d516-c7d7-466d-9f95-8e7831eab866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "class_names = ['___', '___', '___'] \n",
    "image_path = 'testbetiktree.jpg'\n",
    "result, probabilities = predict_image(model, image_path, class_names)\n",
    "print(result)\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e443037-63ba-456c-8988-c289f7aa76cc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook provides a template for loading and using a custom-trained ResNet-50 model on Jetson devices. Modify the code to suit your specific use case, such as adjusting the number of output classes or updating the image preprocessing steps."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
